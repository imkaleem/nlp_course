{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948fc274",
   "metadata": {},
   "source": [
    "# Module 1, Week 1, Assignment 1: Tokenization and Preprocessing\n",
    "\n",
    "In this assignment, you will explore the fundamentals of text preprocessing, a critical step in any NLP workflow. Follow the instructions provided in the notebook and complete the activities to solidify your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bee2f4",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Understand the importance of text preprocessing in NLP.\n",
    "- Learn to tokenize text into sentences and words.\n",
    "- Remove punctuation and special characters from text.\n",
    "- Perform basic normalization by converting text to lowercase.\n",
    "- Use NLTK to remove stopwords from the text.\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions:\n",
    "1. Run the provided code cells to see examples of preprocessing techniques.\n",
    "2. Complete the **TODO** sections to practice your skills.\n",
    "3. Analyze and compare the raw vs. preprocessed text in the final activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51db24",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "First, we will import the libraries needed for tokenization and text preprocessing. NLTK will be the primary library for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd47b189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kaleem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaleem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download required NLTK data files\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('stopwords')  # For stopword removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097beb1",
   "metadata": {},
   "source": [
    "## Step 2: Tokenization\n",
    "Tokenization is the process of breaking down text into smaller units, such as words or sentences. Let's practice tokenizing a sample paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94495a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:\n",
      " ['Natural Language Processing (NLP) is a fascinating field of artificial intelligence.', 'It focuses on the interaction between computers and human language.', 'Tokenization is a crucial step in NLP pipelines!']\n",
      "\n",
      "Word Tokenization:\n",
      " ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', '.', 'It', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'human', 'language', '.', 'Tokenization', 'is', 'a', 'crucial', 'step', 'in', 'NLP', 'pipelines', '!']\n"
     ]
    }
   ],
   "source": [
    "# Example Text\n",
    "text = \"Natural Language Processing (NLP) is a fascinating field of artificial intelligence. It focuses on the interaction between computers and human language. Tokenization is a crucial step in NLP pipelines!\"\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\\n\", sentences)\n",
    "\n",
    "# Word Tokenization\n",
    "words = word_tokenize(text)\n",
    "print(\"\\nWord Tokenization:\\n\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22e81c-3a43-4fa6-bf19-02fbffb5bb5f",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e99d5b2-f63a-44ab-a630-851c2008e363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:\n",
      " ['Machine learning is a subset of artificial intelligence.', 'It allows computers to learn from data without explicit programming.', 'Techniques such as supervised learning and reinforcement learning are used in various applications.']\n",
      "\n",
      "Word Tokenization:\n",
      " ['Machine', 'learning', 'is', 'a', 'subset', 'of', 'artificial', 'intelligence', '.', 'It', 'allows', 'computers', 'to', 'learn', 'from', 'data', 'without', 'explicit', 'programming', '.', 'Techniques', 'such', 'as', 'supervised', 'learning', 'and', 'reinforcement', 'learning', 'are', 'used', 'in', 'various', 'applications', '.']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Tokenize another sample paragraph of your choice\n",
    "# Add your own text below and apply sentence and word tokenization\n",
    "text_custom = \"Machine learning is a subset of artificial intelligence. It allows computers to learn from data without explicit programming. Techniques such as supervised learning and reinforcement learning are used in various applications.\"\n",
    "sentences_custom = sent_tokenize(text_custom)\n",
    "print(\"Sentence Tokenization:\\n\", sentences_custom)\n",
    "words_custom = word_tokenize(text_custom)\n",
    "print(\"\\nWord Tokenization:\\n\", words_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3a099",
   "metadata": {},
   "source": [
    "## Step 3: Removing Punctuation and Special Characters\n",
    "Punctuation and special characters often don't carry meaningful information for NLP tasks. Removing them can help simplify the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99a19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without punctuation:\n",
      " Natural Language Processing NLP is a fascinating field of artificial intelligence It focuses on the interaction between computers and human language Tokenization is a crucial step in NLP pipelines\n"
     ]
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "text_no_punct = text.translate(str.maketrans('', '', string.punctuation))\n",
    "print(\"Text without punctuation:\\n\", text_no_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1235b9-871b-40b9-9e48-ee847cc3443b",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12cac592-f103-4800-9b95-74a233a3eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without punctuation:\n",
      " Machine learning is a subset of artificial intelligence It allows computers to learn from data without explicit programming Techniques such as supervised learning and reinforcement learning are used in various applications\n"
     ]
    }
   ],
   "source": [
    "# TODO: Remove punctuation from your custom text (from Step 2)\n",
    "text_custom_no_punct = text_custom.translate(str.maketrans('', '', string.punctuation))\n",
    "print(\"Text without punctuation:\\n\", text_custom_no_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5979a8",
   "metadata": {},
   "source": [
    "## Step 4: Lowercasing and Normalization\n",
    "Normalization involves converting text to a consistent format, such as lowercasing, to reduce variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd21ddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased Text:\n",
      " natural language processing nlp is a fascinating field of artificial intelligence it focuses on the interaction between computers and human language tokenization is a crucial step in nlp pipelines\n"
     ]
    }
   ],
   "source": [
    "# Convert Text to Lowercase\n",
    "text_lower = text_no_punct.lower()\n",
    "print(\"Lowercased Text:\\n\", text_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df11f83-9c3a-4df1-9fbe-3d57a1a98e4d",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72600857-c2da-43db-8ed4-65fb9ff66fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased Text:\n",
      " machine learning is a subset of artificial intelligence it allows computers to learn from data without explicit programming techniques such as supervised learning and reinforcement learning are used in various applications\n"
     ]
    }
   ],
   "source": [
    "# TODO: Apply lowercasing to your custom text (from Step 3)\n",
    "text_custom_lower = text_custom_no_punct.lower()\n",
    "print(\"Lowercased Text:\\n\", text_custom_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5205e4",
   "metadata": {},
   "source": [
    "## Step 5: Removing Stopwords\n",
    "Stopwords are common words (e.g., \"and\", \"the\", \"is\") that often do not add much meaning to a sentence. Removing stopwords can help focus on the more meaningful words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a277ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without stopwords:\n",
      " ['natural', 'language', 'processing', 'nlp', 'fascinating', 'field', 'artificial', 'intelligence', 'focuses', 'interaction', 'computers', 'human', 'language', 'tokenization', 'crucial', 'step', 'nlp', 'pipelines']\n"
     ]
    }
   ],
   "source": [
    "# Define Stopword List\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove Stopwords\n",
    "words_no_stopwords = [word for word in word_tokenize(text_lower) if word not in stop_words]\n",
    "print(\"Text without stopwords:\\n\", words_no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33e273-2417-4d59-b6ca-591a62232a8a",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c1e4f0-3ebd-40f3-ae42-abb9d328a1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without stopwords:\n",
      " ['machine', 'learning', 'subset', 'artificial', 'intelligence', 'allows', 'computers', 'learn', 'data', 'without', 'explicit', 'programming', 'techniques', 'supervised', 'learning', 'reinforcement', 'learning', 'used', 'various', 'applications']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Remove stopwords from your custom text (from Step 4)\n",
    "words_custom_no_stopwords = [word for word in word_tokenize(text_custom_lower) if word not in stop_words]\n",
    "print(\"Text without stopwords:\\n\", words_custom_no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f2de7",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Raw vs. Preprocessed Text\n",
    "Compare the original text with the preprocessed version to understand the impact of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb06cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Natural Language Processing (NLP) is a fascinating field of artificial intelligence. It focuses on the interaction between computers and human language. Tokenization is a crucial step in NLP pipelines!\n",
      "\n",
      "Preprocessed Text:\n",
      " natural language processing nlp fascinating field artificial intelligence focuses interaction computers human language tokenization crucial step nlp pipelines\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\\n\", text)\n",
    "print(\"\\nPreprocessed Text:\\n\", ' '.join(words_no_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc43a1-e010-4fd0-ac08-377bff2adcb7",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1c9499-1b5f-4349-a1ef-27680e846656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Original Text:\n",
      " Machine learning is a subset of artificial intelligence. It allows computers to learn from data without explicit programming. Techniques such as supervised learning and reinforcement learning are used in various applications.\n",
      "\n",
      "Custom Preprocessed Text:\n",
      " machine learning subset artificial intelligence allows computers learn data without explicit programming techniques supervised learning reinforcement learning used various applications\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the original and preprocessed versions of your custom text\n",
    "print(\"Custom Original Text:\\n\", text_custom)\n",
    "print(\"\\nCustom Preprocessed Text:\\n\", ' '.join(words_custom_no_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb928d",
   "metadata": {},
   "source": [
    "### Congratulations! 🎉\n",
    "You have completed the tokenization and preprocessing assignment. These preprocessing steps are foundational in NLP workflows and will help you tackle more advanced topics in the future.\n",
    "\n",
    "---\n",
    "\n",
    "## Reflection:\n",
    "- How did removing punctuation and stopwords change the text?\n",
    "- Were there any cases where removing stopwords might not have been ideal?\n",
    "\n",
    "Feel free to experiment with more text samples and explore additional preprocessing techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc575ca-5cff-49ff-8303-35ea81241fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
