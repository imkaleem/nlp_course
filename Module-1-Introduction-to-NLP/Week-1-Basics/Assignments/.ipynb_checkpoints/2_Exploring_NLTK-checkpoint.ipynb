{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8438d797",
   "metadata": {},
   "source": [
    "# Module 1, Week 1, Assignment 2: Exploring NLTK\n",
    "\n",
    "In this assignment, you'll explore NLTK (Natural Language Toolkit), a powerful library for building NLP applications. You'll work on tasks like tagging, parsing, and basic text analysis using NLTK's capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "- Learn to perform Part-of-Speech (POS) tagging using NLTK.\n",
    "- Explore Named Entity Recognition (NER).\n",
    "- Use NLTK to calculate word frequency distribution in text.\n",
    "- Understand basic parsing techniques with NLTK.\n",
    "\n",
    "### Instructions:\n",
    "1. Follow the examples and explanations in each section.\n",
    "2. Complete the **TODO** tasks to practice.\n",
    "3. Reflect on the output and experiment with different texts.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4c447",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries and Download Data\n",
    "We'll begin by importing NLTK and downloading the necessary datasets for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Download Required NLTK Data Files\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')  # For POS tagging\n",
    "nltk.download('maxent_ne_chunker')  # For NER\n",
    "nltk.download('words')  # For NER\n",
    "nltk.download('gutenberg')  # Sample texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2f613",
   "metadata": {},
   "source": [
    "## Step 2: Part-of-Speech (POS) Tagging\n",
    "POS tagging involves labeling each word in a sentence with its grammatical role (e.g., noun, verb, adjective). This is crucial for understanding the structure of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Text\n",
    "text = \"Natural Language Processing helps computers understand human language.\"\n",
    "\n",
    "# Tokenize and Apply POS Tagging\n",
    "tokens = word_tokenize(text)\n",
    "pos_tags = pos_tag(tokens)\n",
    "print(\"POS Tags:\\n\", pos_tags)\n",
    "\n",
    "# TODO: Perform POS tagging on a custom sentence\n",
    "# text_custom = \"Your custom sentence here.\"\n",
    "# tokens_custom = word_tokenize(text_custom)\n",
    "# pos_tags_custom = pos_tag(tokens_custom)\n",
    "# print(\"\\nPOS Tags for Custom Text:\\n\", pos_tags_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd355d46",
   "metadata": {},
   "source": [
    "## Step 3: Named Entity Recognition (NER)\n",
    "NER identifies and classifies entities in text, such as names of people, organizations, locations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424afaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NER on the Sample Text\n",
    "ner_tree = ne_chunk(pos_tags)\n",
    "print(\"Named Entities:\")\n",
    "for subtree in ner_tree:\n",
    "    if isinstance(subtree, Tree):\n",
    "        print(subtree)\n",
    "\n",
    "# TODO: Perform NER on your custom sentence from Step 2\n",
    "# ner_tree_custom = ne_chunk(pos_tags_custom)\n",
    "# print(\"\\nNamed Entities for Custom Text:\")\n",
    "# for subtree in ner_tree_custom:\n",
    "#     if isinstance(subtree, Tree):\n",
    "#         print(subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f284267",
   "metadata": {},
   "source": [
    "## Step 4: Word Frequency Distribution\n",
    "Analyzing the frequency of words in a text helps identify common themes or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1517e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Text for Frequency Distribution\n",
    "sample_text = nltk.corpus.gutenberg.raw('austen-emma.txt')[:500]\n",
    "tokens_sample = word_tokenize(sample_text)\n",
    "\n",
    "# Calculate Frequency Distribution\n",
    "fdist = FreqDist(tokens_sample)\n",
    "print(\"Most Common Words:\\n\", fdist.most_common(10))\n",
    "\n",
    "# Plot Frequency Distribution\n",
    "fdist.plot(10, title=\"Top 10 Words in Sample Text\")\n",
    "\n",
    "# TODO: Perform frequency distribution analysis on a custom paragraph\n",
    "# custom_text = \"Your custom paragraph here.\"\n",
    "# tokens_custom = word_tokenize(custom_text)\n",
    "# fdist_custom = FreqDist(tokens_custom)\n",
    "# print(\"\\nMost Common Words in Custom Text:\\n\", fdist_custom.most_common(10))\n",
    "# fdist_custom.plot(10, title=\"Top 10 Words in Custom Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384d853",
   "metadata": {},
   "source": [
    "## Step 5: Parsing Sentences\n",
    "Parsing involves analyzing the grammatical structure of a sentence. NLTK provides tools for syntactic parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Simple Grammar for Parsing\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  NP -> DT NN\n",
    "  VP -> VBZ NP\n",
    "  DT -> 'the'\n",
    "  NN -> 'cat' | 'mat'\n",
    "  VBZ -> 'sits'\n",
    "\"\"\")\n",
    "\n",
    "# Create a Parser\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "# Parse a Sentence\n",
    "sentence = ['the', 'cat', 'sits', 'the', 'mat']\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)\n",
    "    tree.draw()\n",
    "\n",
    "# TODO: Define a custom grammar and parse a new sentence\n",
    "# custom_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "# Your custom grammar here\n",
    "# \"\"\")\n",
    "# custom_parser = nltk.ChartParser(custom_grammar)\n",
    "# custom_sentence = [\"Your\", \"custom\", \"sentence\", \"tokens\"]\n",
    "# for tree in custom_parser.parse(custom_sentence):\n",
    "#     print(tree)\n",
    "#     tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966abc4",
   "metadata": {},
   "source": [
    "### Congratulations! ðŸŽ‰\n",
    "You have completed the second assignment on exploring NLTK. You've worked with POS tagging, NER, frequency distribution, and basic parsing, which are foundational skills for NLP tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### Reflection:\n",
    "- How does NER help in extracting important information from text?\n",
    "- What insights can you gain from word frequency distribution?\n",
    "- Experiment with different grammars and sentences in parsing. What challenges do you encounter?\n",
    "\n",
    "Feel free to expand on these techniques and explore NLTK's additional functionalities!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
